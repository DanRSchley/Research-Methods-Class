<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Research Methods</title>
  <link rel="stylesheet" href="style.css" />
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }
    header {
      background-color: #003366;
      color: white;
      padding: 1.5rem 2rem;
      text-align: center;
    }
    nav ul {
      list-style: none;
      padding: 0;
      margin: 1rem 0 0;
      display: flex;
      justify-content: center;
      gap: 2rem;
    }
    nav ul li a {
      color: #cce6ff;
      text-decoration: none;
      font-weight: bold;
    }
    nav ul li a:hover {
      color: white;
    }
    main {
      max-width: 800px;
      margin: 2rem auto;
      padding: 1rem 2rem;
      background-color: white;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }
    h1 {
      font-size: 1.8rem;
    }
    h2 {
      color: #003366;
    }
    footer {
      text-align: center;
      padding: 1rem;
      background-color: #003366;
      color: white;
      position: relative;
      bottom: 0;
      width: 100%;
      margin-top: 2rem;
    }
    .resource-list {
      margin-top: 1rem;
      padding-left: 1rem;
    }
    .resource-list li {
      margin: 0.5rem 0;
    }
    .resource-list a {
      color: #003366;
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <header>
    <h1>Advanced Research Methods: Measurement, Hypothesis Testing and Experimentation, and Causal Inference</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="resources.html">Course Materials</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <section>
  <p>
  Welcome to our workshop in measurement, hypothesis testing, experimentation, and causal inference. These topics are often taught in separate courses and presented with different terminology and conceptual emphases, even though they address tightly connected problems. A central goal of this workshop is to bring these approaches together within a single integrated framework and a shared lexicon for talking about how we measure constructs, implement experimental designs, and draw causal conclusions. Establishing this common language helps bridge methodological traditions that are often siloed and allows researchers to more clearly connect theory, design, analysis, and interpretation.
</p>

<p>
  Participants will learn that causal inference ultimately rests on the assumptions required for hypothesis testing in experimental and non-experimental settings, and that those assumptions themselves depend on the quality of measurement. Throughout the workshop, we work through a linked set of examples that show how decisions made at the measurement stage propagate forward into experimental design and, finally, shape our ability to draw credible causal conclusions. Rather than treating these topics as isolated toolkits, the workshop emphasizes how they form a single pipeline of reasoning about data and evidence.
</p>

<p>
  The first module introduces key principles of psychometrics for those without formal training in latent-variable modeling. Instead of focusing on abstract methods, the module applies psychometric reasoning directly to the kinds of experiments common in the <em>Journal of Consumer Research</em> and to the more structural modeling approaches typically found in <em>Marketing Science</em>. Participants learn how psychological constructs are inferred from imperfect measurements, how reliability and validity depend jointly on the nature of the construct and the instrument used to assess it, and how these choices shape what can meaningfully be tested or estimated in any empirical study.
</p>

<p>
  The second module turns to hypothesis testing and experimentation. While many researchers are comfortable with standard experimental designs, the assumptions that distinguish clean experimental inference from quasi-experimental or observational claims are often left implicit. Building directly on Module 1, this section treats not only outcome measures but also predictors, manipulations, and treatments as latent variables that are implemented with noise and potential bias. Participants examine how issues such as manipulation strength, treatment heterogeneity, noncompliance, and construct validity affect causal interpretation. In addition to reviewing conventional psychology-style experiments, this module introduces more advanced experimental designs that better accommodate complex treatments, partial compliance, clustered or multi-level settings, and strategic or dynamic response patterns that frequently arise in applied research.
</p>

<p>
  The third module covers modern frameworks and tools for formal causal inference, including both counterfactual (Rubin) and graphical/structural (Pearl) approaches. Participants learn how these methods extend the logic developed in the first two modules by formalizing assumptions about identification, confounding, and generalization. The emphasis is on how causal models remain grounded in earlier measurement and operationalization choices: identification strategies and adjustment techniques cannot compensate for poorly defined or poorly measured constructs. Through applied examples, we connect measurement design, experimental structure, and causal estimation into a unified workflow.
</p>

<p>
  For most topics, the workshop presents paired examples: one experimental example to demonstrate concepts commonly encountered in laboratory or field experiments, and one secondary-data or observational example to illustrate how the same principles apply in more econometric or large-scale modeling contexts. Across both domains, we highlight recurring pitfalls that stem from inconsistent terminology, misaligned assumptions, or isolated treatment of measurement, design, and causal inference rather than viewing them as parts of an integrated analytical process.
</p>

<p>
  Workshop participants should already have experience with the basic tools and concepts associated with experimental research (see the prerequisite topics appended to this document). Several terms from this list also appear in the syllabus because the goal is not simply review but conceptual refinement. For example, while participants may enter the workshop with a working understanding of “reliability” and “validity,” they will develop a more precise appreciation of how these concepts depend on the joint evaluation of both the theoretical construct and the properties of the measurement device used to capture it. The workshop aims to deepen participants’ command of such foundational terms so they can be used consistently across measurement, experimental design, and causal modeling.
</p>

<p>
  At its core, scientific inference combines observed data with a set of assumptions to reason about latent processes and generalizable effects. This makes it essential to understand not only our statistical methods, but also the assumptions embedded in measurement design, experimental implementation, and causal identification. Many empirical errors arise not from technical mistakes but from failure to recognize the consequences of these assumptions or to articulate them clearly. By the end of the workshop, participants will be able to systematically identify both the explicit and implicit assumptions in a published study and assess how those assumptions shape interpretation, credibility, and scope of generalization.
</p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 Dan R. Schley</p>
  </footer>
</body>
</html>
